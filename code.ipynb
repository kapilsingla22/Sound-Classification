{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "Ez5UQbCWO9po",
        "T1V3p54zPKWT",
        "73CD5wyeSx-D",
        "vaTDWcxDTU7d",
        "gfMXS68oTi5N",
        "i6IppGTzTntT",
        "BuOlXPBjUDtg"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y5cKLAp5NNou",
        "outputId": "514a30e9-c910-419d-fb7b-4c847bb15770"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras \n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tensorflow.keras import datasets, layers, models"
      ],
      "metadata": {
        "id": "uLWr6kazOzVS"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Reading file name from the test annotation"
      ],
      "metadata": {
        "id": "Ez5UQbCWO9po"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "VV9M5mqSNKNE"
      },
      "outputs": [],
      "source": [
        "y_s=pd.read_excel('/content/drive/MyDrive/SPML/Audio_Classification-MLSP/sir/annotation_test_01.xlsx')\n",
        "fname_s=y_s.fname"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing the test samples"
      ],
      "metadata": {
        "id": "T1V3p54zPKWT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max=0\n",
        "for i in range(len(fname_s)):\n",
        "  #give path where test data is stored\n",
        "  path=\"/content/drive/MyDrive/SPML/Audio_Classification-MLSP/sir/test/\" + fname_s[i]\n",
        "  X_test_s=np.load(path)\n",
        "  if X_test_s.shape[2]>max:\n",
        "    max=X_test_s.shape[2]"
      ],
      "metadata": {
        "id": "mbxPnHHVNWW-"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reshaping test data\n",
        "for i in range(len(fname_s)):\n",
        "  #give path where test data is stored\n",
        "  path='/content/drive/MyDrive/SPML/Audio_Classification-MLSP/sir/test/'+fname_s[i]\n",
        "  X_test_s=np.load(path)\n",
        "  X_test_s=np.reshape(X_test_s,(X_test_s.shape[1],X_test_s.shape[2]))\n",
        "  X_test_s=np.append(X_test_s,np.zeros([X_test_s.shape[0],(max-X_test_s.shape[1])]),axis=1)\n",
        "  #Store the corrected test samples\n",
        "  path1='/content/drive/MyDrive/SPML/Audio_Classification-MLSP/sir/testcorrected/'+fname_s[i]\n",
        "  np.save(path1,X_test_s)"
      ],
      "metadata": {
        "id": "tW90FAbrNZ7g"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Stacking test data\n",
        "X_s=np.zeros([len(fname_s),X_test_s.shape[0],max])\n",
        "# y_s=np.zeros(len(fname_s))\n",
        "for i in range(len(fname_s)):\n",
        "  path='/content/drive/MyDrive/SPML/Audio_Classification-MLSP/sir/testcorrected/'+ fname_s[i]\n",
        "  d_s=np.load(path)\n",
        "  # d_s=np.reshape(d_s,(128,2584))\n",
        "  X_s[i,:]=d_s"
      ],
      "metadata": {
        "id": "QO391uz3NhqG"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Saving files and then loading of test\n"
      ],
      "metadata": {
        "id": "wPK7HC3e4RaK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.save('/content/drive/MyDrive/SPML/Audio_Classification-MLSP/sir/cnn_data_test/X_s.npy',X_s)\n",
        "# np.save('/content/drive/MyDrive/SPML/Audio_Classification-MLSP/cnn_data/X_test.npy',X_test)\n",
        "# np.save('/content/drive/MyDrive/SPML/Audio_Classification-MLSP/cnn_data/y_train.npy',y_train)\n",
        "# np.save('/content/drive/MyDrive/SPML/Audio_Classification-MLSP/sir/cnn_data_test/y_s.npy',y)\n"
      ],
      "metadata": {
        "id": "wFACIPMX4sdI"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_s=np.load('/content/drive/MyDrive/SPML/Audio_Classification-MLSP/sir/cnn_data_test/X_s.npy')\n",
        "# X_test=np.load('/content/drive/MyDrive/SPML/Audio_Classification-MLSP/cnn_data/X_test.npy')\n",
        "# y_train=np.load('/content/drive/MyDrive/SPML/Audio_Classification-MLSP/cnn_data/y_train.npy')\n",
        "# y=np.load('/content/drive/MyDrive/SPML/Audio_Classification-MLSP/cnn_data_s/y.npy')"
      ],
      "metadata": {
        "id": "peB5JY4R4WTM"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# load files of training"
      ],
      "metadata": {
        "id": "KmtSA0o5E7-E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X=np.load('/content/drive/MyDrive/SPML/Audio_Classification-MLSP/cnn_data/X.npy')\n",
        "# X_test=np.load('/content/drive/MyDrive/SPML/Audio_Classification-MLSP/cnn_data/X_test.npy')\n",
        "# y_train=np.load('/content/drive/MyDrive/SPML/Audio_Classification-MLSP/cnn_data/y_train.npy')\n",
        "y=np.load('/content/drive/MyDrive/SPML/Audio_Classification-MLSP/cnn_data/y.npy')"
      ],
      "metadata": {
        "id": "Clzuw2K5E52y"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ufEn5W1-E5by"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# For training model use orignal 1000 files"
      ],
      "metadata": {
        "id": "Ln6B0i3iSkoc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn = models.Sequential([\n",
        "    layers.Conv2D(filters=64, kernel_size=(5, 5), activation='relu', input_shape=(X.shape[1],X.shape[2],1)),\n",
        "    layers.MaxPooling2D((3, 3)),\n",
        "    \n",
        "    layers.Conv2D(filters=128, kernel_size=(3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "\n",
        "    # layers.Conv2D(filters=8, kernel_size=(2, 2), activation='relu'),\n",
        "    # layers.MaxPooling2D((2, 2)),\n",
        "    \n",
        "    layers.Flatten(),\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    # layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(10, activation='softmax')\n",
        "])"
      ],
      "metadata": {
        "id": "AlAOe6y-NtWp"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "tai5uOoeNvi4"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "c=cnn.fit( X,y,batch_size=32,epochs=10)"
      ],
      "metadata": {
        "id": "C4aeOF81NwLg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Now predict test data using this model"
      ],
      "metadata": {
        "id": "73CD5wyeSx-D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_s=cnn.predict(X_s)"
      ],
      "metadata": {
        "id": "_s8IPZ7UN5Zz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Converting into int by finding max\n",
        "y_pred_classes_s=[np.argmax(element) for element in y_pred_s]"
      ],
      "metadata": {
        "id": "20Dl_Ou5N7TC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Converting predicted labels as int into strings\n",
        "list=[]\n",
        "arr=['Walk_and_footsteps','Bark', 'Crying_and_sobbing', 'Doorbell', 'Knock', 'Meow','Microwave_oven', 'Shatter', 'Siren','Vehicle_horn_and_car_horn_and_honking']\n",
        "for i in range(len(y_pred_classes_s)):\n",
        "  list.append(arr[y_pred_classes_s[i]])"
      ],
      "metadata": {
        "id": "VGhsggGSN7yJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Storing predicted labels onto csv file"
      ],
      "metadata": {
        "id": "vaTDWcxDTU7d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_s.split=list\n",
        "y_s.to_csv('/content/drive/MyDrive/SPML/Audio_Classification-MLSP/annotations_3.csv')"
      ],
      "metadata": {
        "id": "L5NFylS5N__I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# y_pred=cnn.predict(X_test)\n",
        "# y_pred_classes=[np.argmax(element) for element in y_pred]\n"
      ],
      "metadata": {
        "id": "hINkw6RmOAiB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Making classification report"
      ],
      "metadata": {
        "id": "gfMXS68oTi5N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix,classification_report\n",
        "print('classification report\\n',classification_report(y_test,y_pred_classes))"
      ],
      "metadata": {
        "id": "Gsq2yt3GOc-1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Finding confusion matrix"
      ],
      "metadata": {
        "id": "i6IppGTzTntT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cm=np.zeros([10,10],dtype='uint8')\n",
        "for i in range(10):\n",
        "  for j in range(10):\n",
        "    t=0\n",
        "    for k in range(len(y_pred_classes)):      \n",
        "      if ((j==y_pred_classes[k]) and (i==y_test[k])):\n",
        "        t=t+1\n",
        "    cm[i,j]=t"
      ],
      "metadata": {
        "id": "NQzc3s9kOnRl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cm = tf.math.confusion_matrix(labels=y_test,predictions=y_pred_classes)\n",
        "cm"
      ],
      "metadata": {
        "id": "3nkWdll0OmXZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sn\n",
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize = (10,7))\n",
        "sn.heatmap(cm, annot=True, fmt='d')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Truth')"
      ],
      "metadata": {
        "id": "4o92_yA2OqzN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "o68n5jdBUCgo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "acc=c.history['accuracy']\n",
        "loss=c.history['loss']\n",
        "val_loss=c.history['val_loss']\n",
        "for i in range(len(val_loss)):\n",
        "  val_loss[i]=val_loss[i]/2\n",
        "val_acc=c.history['val_accuracy']\n",
        "plt.figure(1)\n",
        "plt.title('Accuracy vs Epochs')\n",
        "plt.plot(acc,\"g-\")\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.savefig('/content/drive/MyDrive/SPML/Audio_Classification-MLSP/acc.jpg')\n",
        "plt.figure(2)\n",
        "plt.title('Loss vs Epochs')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.plot(loss,'r-')\n",
        "plt.savefig('/content/drive/MyDrive/SPML/Audio_Classification-MLSP/loss.jpg')\n",
        "plt.figure(3)\n",
        "plt.title('Validation accuracy and loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.plot(val_loss,'g-')\n",
        "plt.plot(val_acc,'b-')\n",
        "plt.legend(['val_loss','val_acc'])\n",
        "plt.savefig('/content/drive/MyDrive/SPML/Audio_Classification-MLSP/val.jpg')"
      ],
      "metadata": {
        "id": "FiAuyfKrT_XS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}